{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üé¨ Movie Revenue Prediction: Full Pipeline & Comparison\n",
                "\n",
                "Notebook n√†y s·∫Ω ch·∫°y quy tr√¨nh **End-to-End** t·ª´ A-Z v√† so s√°nh tr·ª±c ti·∫øp hi·ªáu qu·∫£ gi·ªØa **Phi√™n b·∫£n c≈© (V1)** v√† **Phi√™n b·∫£n n√¢ng cao (V2)**.\n",
                "\n",
                "### üìå Quy tr√¨nh:\n",
                "1.  **Data Loading**: T·∫£i d·ªØ li·ªáu phim (2010-2024).\n",
                "2.  **Experiment 1 (Baseline)**: Ch·∫°y Preprocessing V1 (Old strategy).\n",
                "3.  **Experiment 2 (Advanced)**: Ch·∫°y Preprocessing V2 (New strategy: KNN, RobustScaler, BGE Embeddings).\n",
                "4.  **Comparison**: So s√°nh R2 Score & MAE.\n",
                "5.  **Final Model & Data**: L∆∞u l·∫°i m√¥ h√¨nh v√† d·ªØ li·ªáu (Train/Test) t·ª´ V2."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Project Root: d:\\Movie_Revenue_Prediction_v2\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore') # T·∫Øt warning cho g·ªçn\n",
                "\n",
                "# Setup Path\n",
                "current_dir = Path(os.getcwd())\n",
                "if current_dir.name == 'notebooks':\n",
                "    project_root = current_dir.parent\n",
                "else:\n",
                "    project_root = current_dir\n",
                "\n",
                "if str(project_root) not in sys.path:\n",
                "    sys.path.append(str(project_root))\n",
                "\n",
                "# Import Modules\n",
                "from src.data_loader import TMDbDataLoader\n",
                "from src.preprocessing import DataPreprocessor        # V1\n",
                "from src.preprocessing_v2 import DataPreprocessorV2   # V2 (New)\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
                "import xgboost as xgb\n",
                "import joblib\n",
                "\n",
                "print(f\"Project Root: {project_root}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:36:53,249 - src.data_loader - INFO - TMDbDataLoader ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading existing data...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:36:53,456 - src.data_loader - INFO - Loaded 2708 rows t·ª´ d:\\Movie_Revenue_Prediction_v2\\data\\raw\\movies_2020_2024.csv\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Data Shape: (2708, 14)\n"
                    ]
                }
            ],
            "source": [
                "config_path = project_root / \"configs\" / \"config.yaml\"\n",
                "raw_data_path = project_root / \"data\" / \"raw\" / \"movies_2020_2024.csv\"\n",
                "\n",
                "loader = TMDbDataLoader(config_path=str(config_path))\n",
                "\n",
                "if not raw_data_path.exists():\n",
                "    print(\"Fetching data from API...\")\n",
                "    loader.fetch_data()\n",
                "    loader.save_data(str(raw_data_path))\n",
                "else:\n",
                "    print(\"Loading existing data...\")\n",
                "\n",
                "df_raw = loader.load_data(str(raw_data_path))\n",
                "print(f\"Data Shape: {df_raw.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Setting Up Experiments (V1 vs V2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_experiment(name, preprocessor, model, df):\n",
                "    print(f\"\\n{'='*20} RUNNING: {name} {'='*20}\")\n",
                "    \n",
                "    # 1. Preprocessing\n",
                "    print(\" Running fit_transform...\")\n",
                "    X, y = preprocessor.fit_transform(df)\n",
                "    print(f\"Features Shape: {X.shape}\")\n",
                "    \n",
                "    # 2. Split\n",
                "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "    \n",
                "    # 3. Train\n",
                "    print(\"Training Model...\")\n",
                "    model.fit(X_train, y_train)\n",
                "    \n",
                "    # 4. Evaluate\n",
                "    y_pred = model.predict(X_test)\n",
                "    r2 = r2_score(y_test, y_pred)\n",
                "    mae = mean_absolute_error(y_test, y_pred)\n",
                "    \n",
                "    print(f\"{name} Results:\")\n",
                "    print(f\"   R2 Score: {r2:.4f}\")\n",
                "    print(f\"   MAE:      ${mae:,.2f}\")\n",
                "    \n",
                "    return {\n",
                "        \"Experiment\": name,\n",
                "        \"R2\": r2,\n",
                "        \"MAE\": mae,\n",
                "        \"Features\": X.shape[1],\n",
                "        \"Test_Samples\": len(y_test),\n",
                "        \"Model\": model,\n",
                "        \"Preprocessor\": preprocessor,\n",
                "        \"Data\": (X_train, X_test, y_train, y_test) # Save data for later\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Run V1 (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:36:53,561 - src.preprocessing - INFO - DataPreprocessor ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng (target_col=revenue, scaler=StandardScaler)\n",
                        "2025-12-07 21:36:53,574 - src.preprocessing - INFO - B·∫Øt ƒë·∫ßu fit preprocessing pipeline...\n",
                        "2025-12-07 21:36:53,612 - src.preprocessing - INFO - ƒê√£ x·ª≠ l√Ω missing values\n",
                        "2025-12-07 21:36:53,646 - src.preprocessing - INFO - ƒê√£ lo·∫°i b·ªè 344 outliers (12.70%)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================== RUNNING: V1 (Basic) ====================\n",
                        " Running fit_transform...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:36:53,707 - src.preprocessing - INFO - ƒê√£ t·∫°o 5 date features\n",
                        "2025-12-07 21:36:53,750 - src.preprocessing - INFO - ƒê√£ encode 19 genres\n",
                        "2025-12-07 21:36:54,118 - src.preprocessing - INFO - ƒê√£ t·∫°o 30 TF-IDF features t·ª´ overview\n",
                        "2025-12-07 21:36:54,130 - src.preprocessing - INFO - ƒê√£ t·∫°o derived features\n",
                        "2025-12-07 21:36:54,147 - src.preprocessing - INFO - ƒê√£ fit preprocessor v·ªõi 65 features\n",
                        "2025-12-07 21:36:54,148 - src.preprocessing - INFO - B·∫Øt ƒë·∫ßu transform data...\n",
                        "2025-12-07 21:36:54,152 - src.preprocessing - INFO - ƒê√£ x·ª≠ l√Ω missing values\n",
                        "2025-12-07 21:36:54,167 - src.preprocessing - INFO - ƒê√£ lo·∫°i b·ªè 344 outliers (12.70%)\n",
                        "2025-12-07 21:36:54,183 - src.preprocessing - INFO - ƒê√£ t·∫°o 5 date features\n",
                        "2025-12-07 21:36:54,193 - src.preprocessing - INFO - ƒê√£ encode 19 genres\n",
                        "2025-12-07 21:36:54,343 - src.preprocessing - INFO - ƒê√£ t·∫°o 30 TF-IDF features t·ª´ overview\n",
                        "2025-12-07 21:36:54,347 - src.preprocessing - INFO - ƒê√£ t·∫°o derived features\n",
                        "2025-12-07 21:36:54,356 - src.preprocessing - INFO - ƒê√£ transform data v·ªõi shape: (2364, 65)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Features Shape: (2364, 65)\n",
                        "Training Model...\n",
                        "V1 (Basic) Results:\n",
                        "   R2 Score: 0.5896\n",
                        "   MAE:      $28,956,918.54\n"
                    ]
                }
            ],
            "source": [
                "# V1: Basic Preprocessing + RandomForest\n",
                "prep_v1 = DataPreprocessor(config_path=str(config_path))\n",
                "model_v1 = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
                "\n",
                "res_v1 = run_experiment(\"V1 (Basic)\", prep_v1, model_v1, df_raw)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Run V2 (Advanced with Embeddings)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:36:56,194 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
                        "2025-12-07 21:36:56,196 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
                        "2025-12-07 21:37:01,957 - src.preprocessing_v2 - INFO - Using Embedding Model: BAAI/bge-small-en-v1.5\n",
                        "2025-12-07 21:37:01,958 - src.preprocessing_v2 - INFO - DataPreprocessorV2 (Advanced) ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.\n",
                        "2025-12-07 21:37:01,965 - src.preprocessing_v2 - INFO - B·∫Øt ƒë·∫ßu fit DataPreprocessorV2 (Advanced)...\n",
                        "2025-12-07 21:37:02,023 - src.preprocessing_v2 - INFO - Encoding overview with BGE Embeddings...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "==================== RUNNING: V2 (Advanced) ====================\n",
                        " Running fit_transform...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:39:33,331 - src.preprocessing_v2 - INFO - ƒê√£ t·∫°o 384 features t·ª´ BGE Embeddings\n",
                        "2025-12-07 21:39:34,526 - src.preprocessing_v2 - INFO - ƒê√£ fit V2 v·ªõi 419 features.\n",
                        "2025-12-07 21:39:35,292 - src.preprocessing_v2 - INFO - Encoding overview with BGE Embeddings...\n",
                        "2025-12-07 21:41:28,402 - src.preprocessing_v2 - INFO - ƒê√£ t·∫°o 384 features t·ª´ BGE Embeddings\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Features Shape: (2708, 419)\n",
                        "Training Model...\n",
                        "V2 (Advanced) Results:\n",
                        "   R2 Score: 0.7671\n",
                        "   MAE:      $53,511,084.00\n"
                    ]
                }
            ],
            "source": [
                "# V2: Advanced Preprocessing (KNN, RobustScaler, BGE) + XGBoost (M·∫°nh h∆°n RF)\n",
                "prep_v2 = DataPreprocessorV2(config_path=str(config_path))\n",
                "# S·ª≠ d·ª•ng XGBoost cho V2 v√¨ n√≥ th∆∞·ªùng handle features t·ªët h∆°n RF\n",
                "model_v2 = xgb.XGBRegressor(n_estimators=200, learning_rate=0.05, n_jobs=-1, random_state=42)\n",
                "\n",
                "res_v2 = run_experiment(\"V2 (Advanced)\", prep_v2, model_v2, df_raw)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Final Comparison & Save Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "LEADERBOARD\n",
                        "      Experiment        R2           MAE  Features\n",
                        "0     V1 (Basic)  0.589595  2.895692e+07        65\n",
                        "1  V2 (Advanced)  0.767092  5.351108e+07       419\n",
                        "\n",
                        "Saving Best Model & Data (V2)...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-12-07 21:41:52,102 - src.preprocessing_v2 - INFO - ƒê√£ l∆∞u preprocessor v√†o: d:\\Movie_Revenue_Prediction_v2\\models\\preprocessor.pkl\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Done! Data saved to 'd:\\Movie_Revenue_Prediction_v2\\data\\processed'\n"
                    ]
                }
            ],
            "source": [
                "# T·ªïng h·ª£p k·∫øt qu·∫£\n",
                "df_results = pd.DataFrame([res_v1, res_v2])\n",
                "cols = ['Experiment', 'R2', 'MAE', 'Features']\n",
                "print(\"\\nLEADERBOARD\")\n",
                "print(df_results[cols])\n",
                "\n",
                "print(\"\\nSaving Best Model & Data (V2)...\")\n",
                "models_dir = project_root / \"models\"\n",
                "processed_dir = project_root / \"data\" / \"processed\"\n",
                "models_dir.mkdir(parents=True, exist_ok=True)\n",
                "processed_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# 1. L∆∞u Model & Preprocessor\n",
                "joblib.dump(res_v2['Model'], models_dir / \"best_model.pkl\")\n",
                "res_v2['Preprocessor'].save_preprocessor(str(models_dir / \"preprocessor.pkl\"))\n",
                "\n",
                "# 2. L∆∞u Processed Data (Train/Test) c·ªßa V2\n",
                "X_train_v2, X_test_v2, y_train_v2, y_test_v2 = res_v2['Data']\n",
                "\n",
                "feature_names = res_v2['Preprocessor'].get_feature_names()\n",
                "# L∆∞u X_train, X_test\n",
                "pd.DataFrame(X_train_v2, columns=feature_names).to_csv(processed_dir / \"X_train.csv\", index=False)\n",
                "pd.DataFrame(X_test_v2, columns=feature_names).to_csv(processed_dir / \"X_test.csv\", index=False)\n",
                "# L∆∞u y_train, y_test\n",
                "pd.DataFrame(y_train_v2, columns=['revenue']).to_csv(processed_dir / \"y_train.csv\", index=False)\n",
                "pd.DataFrame(y_test_v2, columns=['revenue']).to_csv(processed_dir / \"y_test.csv\", index=False)\n",
                "\n",
                "print(f\"Done! Data saved to '{processed_dir}'\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
